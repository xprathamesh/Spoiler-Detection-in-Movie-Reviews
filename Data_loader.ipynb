{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_loader.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"I7OS1_15OJD6","colab_type":"text"},"source":["- The file loads movie data from data files stored on drive\n","- The movie details and reviews data-frames are formatted\n","- Required fields are combined in single data frame\n","- The strings are tokenized to form training data"]},{"cell_type":"code","metadata":{"id":"5TGcd3g029ll","colab_type":"code","outputId":"45cb879d-ca08-4596-e632-8d265a50a479","executionInfo":{"status":"ok","timestamp":1587718836135,"user_tz":240,"elapsed":26374,"user":{"displayName":"Sanveg Rane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4KP8Wtet_KpGow_2tb3tpeQTP0AgihSxO9LME=s64","userId":"03392707856706561796"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["!pip install -q gluonnlp\n","!pip install -q mxnet\n","!pip install PyDrive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |█▎                              | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20kB 4.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 51kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 102kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 112kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 122kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 133kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 143kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 153kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 163kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 174kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 184kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 194kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 204kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 215kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 225kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 235kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 245kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256kB 6.4MB/s \n","\u001b[?25h  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 68.7MB 42kB/s \n","\u001b[?25hRequirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.7.2)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n","Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.2)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (46.1.3)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cX-ublUrGpor","colab_type":"code","colab":{}},"source":["import json, csv, re, nltk\n","\n","import pandas as pd\n","import numpy as np\n","import gluonnlp as nlp\n","\n","from keras.preprocessing.text import Tokenizer\n","\n","from google.colab import auth, drive\n","from oauth2client.client import GoogleCredentials"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7hPQjubwAwwZ","colab_type":"text"},"source":["Accessing data files from google drive\n","\n","- Open the link that opens up and copy the verification code"]},{"cell_type":"code","metadata":{"id":"JKQpGTJLIXHn","colab_type":"code","outputId":"0c524c57-84c7-4826-f8aa-625fe9e4047a","executionInfo":{"status":"ok","timestamp":1587718906017,"user_tz":240,"elapsed":55157,"user":{"displayName":"Sanveg Rane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4KP8Wtet_KpGow_2tb3tpeQTP0AgihSxO9LME=s64","userId":"03392707856706561796"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bRIAsAjg5be7","colab_type":"text"},"source":["Parse the reviews data from json file. Remove duplicate review text and update review date format."]},{"cell_type":"code","metadata":{"id":"NwnnHvrU62s8","colab_type":"code","colab":{}},"source":["def parse_reviews_data(file_loc):\n","  reviews = pd.read_json(file_loc, lines=True).drop_duplicates('review_text').sample(frac=1)\n","\n","  reviews.review_date = pd.to_datetime(reviews.review_date, infer_datetime_format=True)\n","  reviews.user_id = reviews.user_id.astype('category')\n","\n","  review_fields = [field for field in reviews]\n","  return reviews"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tUueMT9NL09c","colab_type":"text"},"source":["Parse the movie data from json file and format relase date format"]},{"cell_type":"code","metadata":{"id":"c_7Uq7BNLMFu","colab_type":"code","colab":{}},"source":["def parse_movie_details_data(file_loc):\n","  details = pd.read_json(file_loc, lines=True)\n","\n","  details.release_date = pd.to_datetime(details.release_date, infer_datetime_format=True)\n","\n","  return details"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TrLG3R_Xdy3f","colab_type":"text"},"source":["Cleaning the punctuations and tokenizing the sentences"]},{"cell_type":"code","metadata":{"id":"PA2K17KhdrB9","colab_type":"code","colab":{}},"source":["def tokenize_text(sentences):\n","  tokenizer = Tokenizer(num_words = None, \\\n","                        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \\\n","                        lower = True, split = ' ')\n","  tokenizer.fit_on_texts(sentences) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hus67X_oPcbA","colab_type":"text"},"source":["Join data sets to extract required fields.\n","Extracting field to prepare training data set\n","\n","Data_type field:\n","- 1: only movie synopses\n","- 2: only moview summary\n","- Otherwise: Larger of synopses or summary"]},{"cell_type":"code","metadata":{"id":"466FS1INNmkW","colab_type":"code","colab":{}},"source":["def merge_datasets(movie_details, user_reviews, id, suffixes, data_type=0):\n","  merged_ds = user_reviews.merge(movie_details, on=id, how=\"left\", suffixes=suffixes)\n","\n","  train = pd.DataFrame(columns=['movie_id', 'sentence_1', 'sentence_2', 'label'])\n","  train['movie_id'] = merged_ds['movie_id']\n","\n","  movie_synopses = pd.Series([str(synopsis) for synopsis in merged_ds['plot_synopsis']])\n","  movie_summary = pd.Series([re.split('\\s*Written by\\s*\\n', \n","                                      str(plot))[0] for plot in merged_ds['plot_summary']])\n","  \n","  if data_type == 1: \n","    train['sentence_1'] = pd.Series([movie_synopses[i] for i in range(len(movie_synopses)) ])\n","  elif data_type == 2:\n","    train['sentence_1'] = pd.Series([movie_summary[i] for i in range(len(movie_summary))])\n","  else:\n","    train['sentence_1'] = pd.Series([movie_synopses[i] \\\n","                                    if len(movie_synopses[i]) > len(movie_summary[i]) else movie_summary[i] \\\n","                                    for i in range(len(movie_synopses))])\n","    \n","  train['sentence_2'] = merged_ds['review_summary'] + ' ' + merged_ds['review_text']\n","\n","  train['label'] = merged_ds['is_spoiler']\n","\n","  train = train.sort_values(by=['label'], ascending=False)\n","\n","  return train"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QtgJOIBqMmiP","colab_type":"text"},"source":["Data Preprocessing:\n","- Loading Reviews data\n","- Loading Movie details data\n","- Performing natural join on movie ID to extract  user's review summary (or title), review detail and the plot synopsis\n","\n","Note: The snippet take execution time as each sentence is converted into tokens"]},{"cell_type":"code","metadata":{"id":"lzYEfjYAMDtW","colab_type":"code","colab":{}},"source":["details_file = '/content/gdrive/My Drive/Colab Notebooks/imdb-spoiler-dataset/IMDB_movie_details.json'\n","reviews_file = '/content/gdrive/My Drive/Colab Notebooks/imdb-spoiler-dataset/IMDB_reviews.json'\n","\n","df_details = parse_movie_details_data(details_file)\n","df_reviews = parse_reviews_data(reviews_file)\n","df_training_data_synps = merge_datasets(df_details, df_reviews, \"movie_id\", ('_review','_movie'), 1)\n","# df_training_data_sumry = merge_datasets(df_details, df_reviews, \"movie_id\", ('_review','_movie'), 2)\n","# df_training_data_combo = merge_datasets(df_details, df_reviews, \"movie_id\", ('_review','_movie'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P4lTdMogbwK2","colab_type":"text"},"source":["Training Data:\n","- Movie ID\n","- Sentence 1: The movie plot summary and plot synopsys\n","- Sentence 2: The review text\n","- Label: Indicates if the review contains a spoiler or not"]},{"cell_type":"code","metadata":{"id":"alBCzOJVZdk5","colab_type":"code","outputId":"7c142266-b3dd-4151-fe8d-804b67ced78b","executionInfo":{"status":"ok","timestamp":1587719073343,"user_tz":240,"elapsed":23106,"user":{"displayName":"Sanveg Rane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4KP8Wtet_KpGow_2tb3tpeQTP0AgihSxO9LME=s64","userId":"03392707856706561796"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["print(df_training_data_synps['label'].value_counts())\n","df_training_data_synps.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["False    422529\n","True     150856\n","Name: label, dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movie_id</th>\n","      <th>sentence_1</th>\n","      <th>sentence_2</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tt1568346</td>\n","      <td>Note: this is an English-language adaptation o...</td>\n","      <td>Confusing, unless you have read the book first...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>441542</th>\n","      <td>tt2404435</td>\n","      <td>In this remake of the 1960 film of the same na...</td>\n","      <td>There Were Seven - They Weren't Magnificent Th...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>179031</th>\n","      <td>tt0408236</td>\n","      <td>Benjamin Barker (Johnny Depp), a skilled barbe...</td>\n","      <td>this movie gave me chills... This movie made m...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>441577</th>\n","      <td>tt3498820</td>\n","      <td>In 1991, Bucky Barnes (Sebastian Stan), brainw...</td>\n","      <td>One of the best Marvel movies This movie helps...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>179040</th>\n","      <td>tt0109830</td>\n","      <td>The film begins with a feather falling to the ...</td>\n","      <td>Life through a different view! This is a lovel...</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         movie_id  ... label\n","0       tt1568346  ...  True\n","441542  tt2404435  ...  True\n","179031  tt0408236  ...  True\n","441577  tt3498820  ...  True\n","179040  tt0109830  ...  True\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"hOEq31GuYPPv","colab_type":"code","colab":{}},"source":["df_training_data_sumry.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_uXrcu_mYQ9D","colab_type":"code","colab":{}},"source":["df_training_data_combo.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LMN6s8eXngkP","colab_type":"text"},"source":["Saving each data to file"]},{"cell_type":"code","metadata":{"id":"EskvrdJ8YaN8","colab_type":"code","colab":{}},"source":["training_file_1_loc = '/content/gdrive/My Drive/Colab Notebooks/imdb-spoiler-dataset/movie_training_data_synps.csv'\n","df_training_data_synps.to_csv(training_file_1_loc, index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRIt12snYjJS","colab_type":"code","colab":{}},"source":["training_file_2_loc = '/content/gdrive/My Drive/Colab Notebooks/imdb-spoiler-dataset/movie_training_data_sumry..csv'\n","df_training_data_sumry.to_csv(training_file_2_loc, index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2lQCR8W2YjFw","colab_type":"code","colab":{}},"source":["training_file_3_loc = '/content/gdrive/My Drive/Colab Notebooks/imdb-spoiler-dataset/movie_training_data_combo.csv'\n","df_training_data_combo.to_csv(training_file_3_loc, index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72rlYomtnOX7","colab_type":"text"},"source":["Converting text to words list"]},{"cell_type":"code","metadata":{"id":"dX5nR189nhO5","colab_type":"code","colab":{}},"source":["target_cols = ['sentence_1','sentence_2']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4Jhv2MJnOEB","colab_type":"code","colab":{}},"source":["def text_to_word_list(text):\n","    text = str(text)\n","    text = text.lower()\n","\n","    # Clean the text\n","    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n","    text = re.sub(r\"what's\", \"what is \", text)\n","    text = re.sub(r\"\\'s\", \" \", text)\n","    text = re.sub(r\"\\'ve\", \" have \", text)\n","    text = re.sub(r\"can't\", \"cannot \", text)\n","    text = re.sub(r\"n't\", \" not \", text)\n","    text = re.sub(r\"i'm\", \"i am \", text)\n","    text = re.sub(r\"\\'re\", \" are \", text)\n","    text = re.sub(r\"\\'d\", \" would \", text)\n","    text = re.sub(r\"\\'ll\", \" will \", text)\n","    text = re.sub(r\",\", \" \", text)\n","    text = re.sub(r\"\\.\", \" \", text)\n","    text = re.sub(r\"!\", \" ! \", text)\n","    text = re.sub(r\"\\/\", \" \", text)\n","    text = re.sub(r\"\\^\", \" ^ \", text)\n","    text = re.sub(r\"\\+\", \" + \", text)\n","    text = re.sub(r\"\\-\", \" - \", text)\n","    text = re.sub(r\"\\=\", \" = \", text)\n","    text = re.sub(r\"'\", \" \", text)\n","    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n","    text = re.sub(r\":\", \" : \", text)\n","    text = re.sub(r\" e g \", \" eg \", text)\n","    text = re.sub(r\" b g \", \" bg \", text)\n","    text = re.sub(r\" u s \", \" american \", text)\n","    text = re.sub(r\"\\0s\", \"0\", text)\n","    text = re.sub(r\" 9 11 \", \"911\", text)\n","    text = re.sub(r\"e - mail\", \"email\", text)\n","    text = re.sub(r\"j k\", \"jk\", text)\n","    text = re.sub(r\"\\s{2,}\", \" \", text)\n","\n","    text = text.split()\n","\n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_vwoC08nXe-","colab_type":"code","colab":{}},"source":["def convert_sentence_to_vector(data_set, target_cols):\n","  for index, row in data_set.iterrows():\n","    for col in target_cols:\n","      embedding = []\n","\n","      for word in text_to_word_list(row[col]):\n","\n","        if word in stops and word not in word_to_vec.vocab: continue\n","\n","        if word not in vocab:\n","          vocab[word] = len(inverse_vocab)\n","          inverse_vocab.append(word)\n","\n","        # add embedded word to embeddings list\n","        embedding.append(vocab[word])\n","      \n","      # converting sentences to embeddings\n","      data_set.at[index, col] = embedding"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TwRmJj5BnaeL","colab_type":"code","colab":{}},"source":["convert_sentence_to_vector(df_training_data, target_cols)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBiRqU_jIrEo","colab_type":"text"},"source":["Save training data to drive"]},{"cell_type":"code","metadata":{"id":"r4cY0KA3AKwd","colab_type":"code","colab":{}},"source":["training_file_loc = '/content/gdrive/My Drive/Colab Notebooks/imdb-spoiler-dataset/movie_training_data.csv'\n","df_training_data.to_csv(training_file_loc, index=False)"],"execution_count":0,"outputs":[]}]}